#!/usr/bin/env python3
"""
Google Indexing API ìë™í™” ìŠ¤í¬ë¦½íŠ¸
sitemap.xmlì˜ ëª¨ë“  URLì„ êµ¬ê¸€ì— ê°•ì œ ì œì¶œí•˜ì—¬ ë¹ ë¥¸ ìƒ‰ì¸ì„ ìš”ì²­í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python google_indexing_submit.py                    # sitemapì˜ ëª¨ë“  URL ì œì¶œ
    python google_indexing_submit.py --dry-run          # í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ì œì¶œ ì•ˆ í•¨)
    python google_indexing_submit.py --check-status     # URL ìƒ‰ì¸ ìƒíƒœ í™•ì¸
    python google_indexing_submit.py --url URL          # íŠ¹ì • URLë§Œ ì œì¶œ
"""

import argparse
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
from urllib.parse import urljoin
import xml.etree.ElementTree as ET

try:
    import requests
    from google.oauth2 import service_account
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
except ImportError:
    print("[ERROR] Required packages not installed!")
    print("\nPlease install with:")
    print("pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client requests")
    sys.exit(1)


# ì„¤ì •
SCRIPT_DIR = Path(__file__).parent
SERVICE_ACCOUNT_FILE = SCRIPT_DIR / 'service-account-key.json'
SCOPES = ['https://www.googleapis.com/auth/indexing']
SITEMAP_URL = 'https://ui-syntax.com/sitemap.xml'
LOG_FILE = SCRIPT_DIR / 'indexing_log.json'

# API ì†ë„ ì œí•œ (ì•ˆì „í•˜ê²Œ)
BATCH_SIZE = 10  # í•œ ë²ˆì— ì²˜ë¦¬í•  URL ê°œìˆ˜
DELAY_BETWEEN_BATCHES = 2  # ë°°ì¹˜ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)


class GoogleIndexingAPI:
    """Google Indexing API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, service_account_file: str):
        """
        Args:
            service_account_file: ì„œë¹„ìŠ¤ ê³„ì • JSON í‚¤ íŒŒì¼ ê²½ë¡œ
        """
        self.service_account_file = service_account_file
        self.service = None
        self._authenticate()
    
    def _authenticate(self):
        """ì„œë¹„ìŠ¤ ê³„ì •ìœ¼ë¡œ ì¸ì¦"""
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.service_account_file,
                scopes=SCOPES
            )
            self.service = build('indexing', 'v3', credentials=credentials)
            print("[OK] Google authentication successful!")
        except FileNotFoundError:
            print(f"[ERROR] Service account key file not found: {self.service_account_file}")
            print("\nGOOGLE_INDEXING_API_SETUP.md íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ ì„¤ì •í•˜ì„¸ìš”!")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ ì¸ì¦ ì‹¤íŒ¨: {str(e)}")
            sys.exit(1)
    
    def submit_url(self, url: str, action: str = "URL_UPDATED") -> Dict[str, Any]:
        """
        URLì„ êµ¬ê¸€ì— ì œì¶œ
        
        Args:
            url: ì œì¶œí•  URL
            action: URL_UPDATED (ì—…ë°ì´íŠ¸) ë˜ëŠ” URL_DELETED (ì‚­ì œ)
        
        Returns:
            API ì‘ë‹µ ë”•ì…”ë„ˆë¦¬
        """
        body = {
            "url": url,
            "type": action
        }
        
        try:
            response = self.service.urlNotifications().publish(body=body).execute()
            return {"success": True, "data": response}
        except HttpError as e:
            error_content = json.loads(e.content.decode('utf-8'))
            return {"success": False, "error": error_content}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_status(self, url: str) -> Dict[str, Any]:
        """
        URLì˜ ìƒ‰ì¸ ìƒíƒœ í™•ì¸
        
        Args:
            url: í™•ì¸í•  URL
        
        Returns:
            ìƒíƒœ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            response = self.service.urlNotifications().getMetadata(url=url).execute()
            return {"success": True, "data": response}
        except HttpError as e:
            error_content = json.loads(e.content.decode('utf-8'))
            return {"success": False, "error": error_content}
        except Exception as e:
            return {"success": False, "error": str(e)}


def fetch_sitemap_urls(sitemap_url: str) -> List[str]:
    """
    sitemap.xmlì—ì„œ ëª¨ë“  URL ì¶”ì¶œ
    
    Args:
        sitemap_url: sitemap.xml URL
    
    Returns:
        URL ë¦¬ìŠ¤íŠ¸
    """
    try:
        print(f"ğŸ“¡ Sitemap ë‹¤ìš´ë¡œë“œ ì¤‘: {sitemap_url}")
        response = requests.get(sitemap_url, timeout=10)
        response.raise_for_status()
        
        # XML íŒŒì‹±
        root = ET.fromstring(response.content)
        
        # XML ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì²˜ë¦¬
        namespaces = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}
        
        # <loc> íƒœê·¸ì—ì„œ ëª¨ë“  URL ì¶”ì¶œ
        urls = [
            loc.text
            for loc in root.findall('.//ns:loc', namespaces)
            if loc.text
        ]
        
        print(f"âœ… {len(urls)}ê°œì˜ URLì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        return urls
    
    except requests.exceptions.RequestException as e:
        print(f"âŒ Sitemap ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        print("\nğŸ’¡ SITEMAP_URL ë³€ìˆ˜ë¥¼ ì‹¤ì œ ì‚¬ì´íŠ¸ ì£¼ì†Œë¡œ ë³€ê²½í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!")
        return []
    except ET.ParseError as e:
        print(f"âŒ Sitemap XML íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        return []


def load_log() -> Dict[str, Any]:
    """ì´ì „ ì œì¶œ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
    log_path = Path(LOG_FILE)
    if log_path.exists():
        with open(log_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"submissions": [], "last_run": None}


def save_log(log_data: Dict[str, Any]):
    """ì œì¶œ ë¡œê·¸ ì €ì¥"""
    with open(LOG_FILE, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, indent=2, ensure_ascii=False)


def submit_urls_batch(api: GoogleIndexingAPI, urls: List[str], dry_run: bool = False):
    """
    URLë“¤ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ ì„œ ì œì¶œ
    
    Args:
        api: GoogleIndexingAPI ì¸ìŠ¤í„´ìŠ¤
        urls: ì œì¶œí•  URL ë¦¬ìŠ¤íŠ¸
        dry_run: Trueë©´ ì‹¤ì œ ì œì¶œ ì•ˆ í•˜ê³  ì‹œë®¬ë ˆì´ì…˜ë§Œ
    """
    total = len(urls)
    success_count = 0
    error_count = 0
    
    log_data = load_log()
    log_data["last_run"] = datetime.now().isoformat()
    current_submissions = []
    
    print(f"\nğŸš€ ì´ {total}ê°œ URL ì œì¶œ ì‹œì‘!")
    print("=" * 60)
    
    for i in range(0, total, BATCH_SIZE):
        batch = urls[i:i + BATCH_SIZE]
        batch_num = (i // BATCH_SIZE) + 1
        total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE
        
        print(f"\nğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘...")
        
        for url in batch:
            if dry_run:
                print(f"  [DRY-RUN] {url}")
                success_count += 1
                continue
            
            result = api.submit_url(url)
            
            submission_log = {
                "url": url,
                "timestamp": datetime.now().isoformat(),
                "success": result["success"]
            }
            
            if result["success"]:
                print(f"  âœ… {url}")
                success_count += 1
                submission_log["response"] = result["data"]
            else:
                print(f"  âŒ {url}")
                print(f"     ì˜¤ë¥˜: {result['error']}")
                error_count += 1
                submission_log["error"] = result["error"]
            
            current_submissions.append(submission_log)
            time.sleep(0.2)  # API ì†ë„ ì œí•œ ë°©ì§€
        
        # ë°°ì¹˜ ê°„ ëŒ€ê¸°
        if i + BATCH_SIZE < total:
            print(f"  â³ {DELAY_BETWEEN_BATCHES}ì´ˆ ëŒ€ê¸° ì¤‘...")
            time.sleep(DELAY_BETWEEN_BATCHES)
    
    # ë¡œê·¸ ì €ì¥
    if not dry_run:
        log_data["submissions"].extend(current_submissions)
        save_log(log_data)
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {error_count}ê°œ")
    print(f"ğŸ“ ì´ ì²˜ë¦¬: {total}ê°œ")
    
    if not dry_run:
        print(f"\nğŸ’¾ ë¡œê·¸ ì €ì¥ë¨: {LOG_FILE}")
    
    if error_count > 0:
        print("\nâš ï¸  ì¼ë¶€ URL ì œì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("   ìì„¸í•œ ë‚´ìš©ì€ ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")


def check_urls_status(api: GoogleIndexingAPI, urls: List[str]):
    """URLë“¤ì˜ ìƒ‰ì¸ ìƒíƒœ í™•ì¸"""
    print(f"\nğŸ” {len(urls)}ê°œ URL ìƒíƒœ í™•ì¸ ì¤‘...")
    print("=" * 60)
    
    for url in urls:
        result = api.get_status(url)
        
        if result["success"]:
            data = result["data"]
            latest = data.get("latestUpdate", {})
            url_type = latest.get("type", "ì•Œ ìˆ˜ ì—†ìŒ")
            notify_time = latest.get("notifyTime", "ì—†ìŒ")
            
            print(f"\nğŸ“„ {url}")
            print(f"   ìƒíƒœ: {url_type}")
            print(f"   ë§ˆì§€ë§‰ ì•Œë¦¼: {notify_time}")
        else:
            print(f"\nğŸ“„ {url}")
            print(f"   âš ï¸  ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {result['error']}")
        
        time.sleep(0.5)


def main():
    parser = argparse.ArgumentParser(
        description="Google Indexing APIë¡œ URLì„ êµ¬ê¸€ì— ê°•ì œ ì œì¶œí•©ë‹ˆë‹¤."
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ì‹¤ì œ ì œì¶œ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ë§Œ ì‹¤í–‰'
    )
    parser.add_argument(
        '--check-status',
        action='store_true',
        help='URLë“¤ì˜ ìƒ‰ì¸ ìƒíƒœ í™•ì¸'
    )
    parser.add_argument(
        '--url',
        type=str,
        help='íŠ¹ì • URLë§Œ ì œì¶œ (sitemap ëŒ€ì‹ )'
    )
    parser.add_argument(
        '--sitemap',
        type=str,
        default=SITEMAP_URL,
        help=f'Sitemap URL (ê¸°ë³¸ê°’: {SITEMAP_URL})'
    )
    
    args = parser.parse_args()
    
    print("ğŸš€ Google Indexing API ìë™í™” ë„êµ¬")
    print("=" * 60)
    
    # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    api = GoogleIndexingAPI(SERVICE_ACCOUNT_FILE)
    
    # URL ê°€ì ¸ì˜¤ê¸°
    if args.url:
        urls = [args.url]
        print(f"ğŸ“Œ íŠ¹ì • URL ëª¨ë“œ: {args.url}")
    else:
        urls = fetch_sitemap_urls(args.sitemap)
        if not urls:
            print("âŒ ì²˜ë¦¬í•  URLì´ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)
    
    # ë™ì‘ ì‹¤í–‰
    if args.check_status:
        check_urls_status(api, urls)
    else:
        submit_urls_batch(api, urls, dry_run=args.dry_run)
        
        if args.dry_run:
            print("\nğŸ’¡ ì‹¤ì œë¡œ ì œì¶œí•˜ë ¤ë©´ --dry-run ì˜µì…˜ ì—†ì´ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”!")
        else:
            print("\nğŸ‰ ì™„ë£Œ! êµ¬ê¸€ì´ ê³§ í¬ë¡¤ë§ì„ ì‹œì‘í•  ê²ë‹ˆë‹¤!")
            print("   Search Consoleì—ì„œ ìƒ‰ì¸ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”:")
            print("   https://search.google.com/search-console")


if __name__ == "__main__":
    main()
